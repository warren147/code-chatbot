myapp-backend  |       [Symbol(kCapture)]: false
myapp-backend  |     },
myapp-backend  |     socketPath: undefined,
myapp-backend  |     method: 'POST',
myapp-backend  |     maxHeaderSize: undefined,
myapp-backend  |     insecureHTTPParser: undefined,
myapp-backend  |     joinDuplicateHeaders: undefined,
myapp-backend  |     path: '/v1/chat/completions',
myapp-backend  |     _ended: true,
myapp-backend  |     res: IncomingMessage {
myapp-backend  |       _readableState: [ReadableState],
myapp-backend  |       _events: [Object: null prototype],
myapp-backend  |       _eventsCount: 4,
myapp-backend  |       _maxListeners: undefined,
myapp-backend  |       socket: [TLSSocket],
myapp-backend  |       httpVersionMajor: 1,
myapp-backend  |       httpVersionMinor: 1,
myapp-backend  |       httpVersion: '1.1',
myapp-backend  |       complete: true,
myapp-backend  |       rawHeaders: [Array],
myapp-backend  |       rawTrailers: [],
myapp-backend  |       joinDuplicateHeaders: undefined,
myapp-backend  |       aborted: false,
myapp-backend  |       upgrade: false,
myapp-backend  |       url: '',
myapp-backend  |       method: null,
myapp-backend  |       statusCode: 400,
myapp-backend  |       statusMessage: 'Bad Request',
myapp-backend  |       client: [TLSSocket],
myapp-backend  |       _consuming: true,
myapp-backend  |       _dumped: false,
myapp-backend  |       req: [Circular *1],
myapp-backend  |       responseUrl: 'https://api.openai.com/v1/chat/completions',
myapp-backend  |       redirects: [],
myapp-backend  |       [Symbol(kCapture)]: false,
myapp-backend  |       [Symbol(kHeaders)]: [Object],
myapp-backend  |       [Symbol(kHeadersCount)]: 52,
myapp-backend  |       [Symbol(kTrailers)]: null,
myapp-backend  |       [Symbol(kTrailersCount)]: 0
myapp-backend  |     },
myapp-backend  |     aborted: false,
myapp-backend  |     timeoutCb: null,
myapp-backend  |     upgradeOrConnect: false,
myapp-backend  |     parser: null,
myapp-backend  |     maxHeadersCount: null,
myapp-backend  |     reusedSocket: false,
myapp-backend  |     host: 'api.openai.com',
myapp-backend  |     protocol: 'https:',
myapp-backend  |     _redirectable: Writable {
myapp-backend  |       _writableState: [WritableState],
myapp-backend  |       _events: [Object: null prototype],
myapp-backend  |       _eventsCount: 3,
myapp-backend  |       _maxListeners: undefined,
myapp-backend  |       _options: [Object],
myapp-backend  |       _ended: true,
myapp-backend  |       _ending: true,
myapp-backend  |       _redirectCount: 0,
myapp-backend  |       _redirects: [],
myapp-backend  |       _requestBodyLength: 17641,
myapp-backend  |       _requestBodyBuffers: [],
myapp-backend  |       _onNativeResponse: [Function (anonymous)],
myapp-backend  |       _currentRequest: [Circular *1],
myapp-backend  |       _currentUrl: 'https://api.openai.com/v1/chat/completions',
myapp-backend  |       [Symbol(kCapture)]: false
myapp-backend  |     },
myapp-backend  |     [Symbol(kCapture)]: false,
myapp-backend  |     [Symbol(kBytesWritten)]: 0,
myapp-backend  |     [Symbol(kNeedDrain)]: false,
myapp-backend  |     [Symbol(corked)]: 0,
myapp-backend  |     [Symbol(kOutHeaders)]: [Object: null prototype] {
myapp-backend  |       accept: [Array],
myapp-backend  |       'content-type': [Array],
myapp-backend  |       authorization: [Array],
myapp-backend  |       'user-agent': [Array],
myapp-backend  |       'content-length': [Array],
myapp-backend  |       'accept-encoding': [Array],
myapp-backend  |       host: [Array]
myapp-backend  |     },
myapp-backend  |     [Symbol(errored)]: null,
myapp-backend  |     [Symbol(kHighWaterMark)]: 16384,
myapp-backend  |     [Symbol(kRejectNonStandardBodyWrites)]: false,
myapp-backend  |     [Symbol(kUniqueHeaders)]: null
myapp-backend  |   },
myapp-backend  |   response: {
myapp-backend  |     status: 400,
myapp-backend  |     statusText: 'Bad Request',
myapp-backend  |     headers: Object [AxiosHeaders] {
myapp-backend  |       date: 'Tue, 04 Nov 2025 00:16:25 GMT',
myapp-backend  |       'content-type': 'application/json',
myapp-backend  |       'content-length': '329',
myapp-backend  |       connection: 'close',
myapp-backend  |       'access-control-expose-headers': 'X-Request-ID',
myapp-backend  |       'openai-organization': 'user-gd3da3va9ysp5nye3mmhbcqk',
myapp-backend  |       'openai-processing-ms': '193',
myapp-backend  |       'openai-project': 'proj_gozVsE39HGN2gk8PjCIvzxrA',
myapp-backend  |       'openai-version': '2020-10-01',
myapp-backend  |       'x-envoy-upstream-service-time': '271',
myapp-backend  |       'x-ratelimit-limit-requests': '10000',
myapp-backend  |       'x-ratelimit-limit-tokens': '10000',
myapp-backend  |       'x-ratelimit-remaining-requests': '9999',
myapp-backend  |       'x-ratelimit-remaining-tokens': '5802',
myapp-backend  |       'x-ratelimit-reset-requests': '8.64s',
myapp-backend  |       'x-ratelimit-reset-tokens': '25.188s',
myapp-backend  |       'x-request-id': 'req_13468b43f8b343a08e76bd6c3217bf12',
myapp-backend  |       'x-openai-proxy-wasm': 'v0.1',
myapp-backend  |       'cf-cache-status': 'DYNAMIC',
myapp-backend  |       'set-cookie': [Array],
myapp-backend  |       'strict-transport-security': 'max-age=31536000; includeSubDomains; preload',
myapp-backend  |       'x-content-type-options': 'nosniff',
myapp-backend  |       server: 'cloudflare',
myapp-backend  |       'cf-ray': '998fec2f4da4a63b-SJC',
myapp-backend  |       'alt-svc': 'h3=":443"; ma=86400'
myapp-backend  |     },
myapp-backend  |     config: {
myapp-backend  |       transitional: [Object],
myapp-backend  |       adapter: [Array],
myapp-backend  |       transformRequest: [Array],
myapp-backend  |       transformResponse: [Array],
myapp-backend  |       timeout: 0,
myapp-backend  |       xsrfCookieName: 'XSRF-TOKEN',
myapp-backend  |       xsrfHeaderName: 'X-XSRF-TOKEN',
myapp-backend  |       maxContentLength: -1,
myapp-backend  |       maxBodyLength: -1,
myapp-backend  |       env: [Object],
myapp-backend  |       validateStatus: [Function: validateStatus],
myapp-backend  |       headers: [Object [AxiosHeaders]],
myapp-backend  |       method: 'post',
myapp-backend  |       url: 'https://api.openai.com/v1/chat/completions',
myapp-backend  |       data: '{"model":"gpt-4","messages":[{"role":"user","content":"\\nYou are an assistant that helps understand and explain code.\\n\\nRelevant Code Snippets:\\n);\\n    \\n    const index = pc.Index(\'code-embeddings\'); \\n\\n  const questionEmbedding = await generateEmbedding(question);\\n\\n  const queryResponse = await index.query({\\n    vector: questionEmbedding,\\n    topK: 5,\\n    includeMetadata: true\\n  });\\n\\n  const relevantSnippets = queryResponse.matches\\n  .map(match => {\\n    const { fileName, chunkIndex, content } = match.metadata;\\n    return `File: ${fileName} (chunk ${chunkIndex})\\n${content}`;\\n  })\\n  .join(\'\\\\n\\\\n\');\\n\\n\\n  const prompt = `\\nYou are a versatile AI coding assistant. The user may request one of several tasks. Based on their question, perform the appropriate action:\\n\\n1. **Summary**: If asked to summarize, provide a high-level overview of what the code does, outline its main components, and describe the overall data flow or algorithmic steps.\\n\\n2. **Debug / Error Identification**: If asked to find problems, analyze the code for bugs, errors, or edge-case failures. For each issue found, explain why it occurs and suggest a precise fix, includi\\n\\n# green_agent/green_server.py\\nfrom __future__ import annotations\\nfrom typing import Any, Dict, List, Optional\\nfrom fastapi import FastAPI, HTTPException, Query\\nfrom fastapi.responses import JSONResponse\\nimport os, uuid, httpx, json\\nfrom .a2a_protocol import HistoryEnvelope, HistoryItem\\n\\ndef _build_full_history_envelope(state) -> dict:\\n    from .a2a_protocol import HistoryEnvelope, HistoryItem\\n    items = []\\n    for msg in state.history:\\n        if isinstance(msg, dict):\\n            if msg.get(\\"type\\") == \\"observation\\" and msg.get(\\"role\\") == \\"green\\":\\n                items.append(HistoryItem(role=\\"user\\", content=msg))\\n            elif msg.get(\\"role\\") == \\"white\\":\\n                items.append(HistoryItem(role=\\"agent\\", content=msg))\\n    return HistoryEnvelope(history=items).dict()\\n\\nfrom .a2a_protocol import (\\n    A2A_VERSION, Observation, ActionProposal, Decision, Feedback,\\n    make_observation, make_feedback_ok, make_feedback_error,\\n    pack_history, validate_action_proposal, validate_decision,\\n    ProposalPolicy,\\n)\\nfrom .evaluator import evaluate_decision_for_task  # <-- centralized metrics\\n\\nWHITE_URL = os.getenv(\\"A2A_WHITE_URL\\", \\"http://localhost:9100/a2a/step\\")\\nALLOWED_DOMAINS = [d.strip() for d in os.getenv(\\"A2A_ALLOWED_DOMAINS\\", \\"localhost,example.org\\").split(\\",\\") if d.strip()]\\nMAX_ROUNDS = 100\\n\\ndef _demo_tasks() -> List[Dict[str, Any]]:\\n    tasks: List[Dict[str, Any]] = []\\n    tasks += [\\n        dict(task_id=\\"service_easy_001\\", persona=\\"ServiceAgent\\", difficulty=\\"easy\\",\\n             instruction=\\"Find the queue handling Billing cases and return its Queue ID.\\",\\n             success_criteria=\\"exact_match_ids\\", ground_truth={\\"id_list\\": [\\"Q-ROUTING-BILLING\\"]}),\\n        dict(task_id=\\"service_medium_002\\", persona=\\"ServiceAgent\\", difficulty=\\"medium\\",\\n             instruction=\\"Compare Billing and Login Issue queues and choose the correct one for a customer billing error.\\",\\n             success_criteria=\\"exact_match_ids\\", ground_truth={\\"id_list\\": [\\"Q-ROUTING-BILLING\\"]}),\\n        dict(task_id=\\"service_hard_003\\", persona=\\"ServiceAgent\\", difficulty=\\"hard\\",\\n             instruction=\\"If a billing error violates refund policy, escalate it to the Policy Escalation queue. Return that Queue ID.\\",\\n             success_criteria=\\"exact_match_ids\\", ground_truth={\\"id_list\\": [\\"Q-ESCALATION-POLICY\\"]}),\\n    ]\\n    tasks += [\\n        dict(task_id=\\"analyst_easy_001\\", persona=\\"Analyst\\", difficulty=\\"easy\\",\\n             instruction=\\"Find which credential is required before performing a warranty replacement.\\",\\n             success_criteria=\\"f1\\", ground_truth={\\"answer_tokens\\": list(set(\\"proof of purchase\\".split()))}),\\n        dict(task_id=\\"analyst_medium_002\\", persona=\\"Analyst\\", difficulty=\\"medium\\",\\n             instruction=\\"Identify the policy that mentions both \'proof of transaction\' and \'proof of purchase\' requirements.\\",\\n             success_criteria=\\"f1\\", ground_truth={\\"answer_tokens\\": list(set(\\"proof of transaction proof of purchase\\".split()))}),\\n        dict(task_id=\\"analyst_hard_003\\", persona=\\"Analyst\\", difficulty=\\"hard\\",\\n             instruction=\\"Using policy and escalation documentation, summarize the process before escalating a warranty dispute.\\",\\n             success_criteria=\\"f1\\", ground_truth={\\"answer_tokens\\": list(set(\\"review policy proof of purchase escalation\\".split()))}),\\n    ]\\n    tasks += [\\n        dict(task_id=\\"manager_easy_001\\", persona=\\"Manager\\", difficulty=\\"easy\\",\\n             instruction=\\"Report the monthly counts of Login Issue cases for the last 3 months as [M-2, M-1, M].\\",\\n             success_criteria=\\"mape\\", ground_truth={\\"series\\": [12, 18, 27]}),\\n        dict(task_id=\\"manager_medium_002\\", persona=\\"Manager\\", difficulty=\\"medium\\",\\n             instruction=\\"Compute the average monthly count over the last 3 months and return approximate monthly values [M-2,M-1,M] that reflect the trend.\\",\\n             success_criteria=\\"mape\\", ground_truth={\\"series\\": [12, 18, 27]}),\\n        dict(task_id=\\"manager_hard_003\\", persona=\\"Manager\\", difficulty=\\"hard\\",\\n             instruction=\\"Predict the next month assuming growth continues. Return [M-2, M-1, M, M+1].\\",\\n             success_criteria=\\"mape\\", ground_truth={\\"series\\": [12, 18, 27, 36]}),\\n    ]\\n    return tasks\\n\\nTASKS = _demo_tasks()\\n\\ndef pick_task(persona: str, difficulty: str) -> Dict[str, Any]:\\n    for t in TASKS:\\n        if t[\\"persona\\"] == persona and t[\\"difficulty\\"] == difficulty:\\n            return t\\n    raise KeyError(f\\"No task for persona={persona}, difficulty={difficulty}\\")\\n\\nclass SessionState:\\n    def __init__(self, session_id: str, persona: str, difficulty: str, task: Dict[str, Any]):\\n        self.session_id = session_id\\n        self.persona = persona\\n        self.difficulty = difficulty\\n        self.task = task\\n        self.turn = 1\\n        self.last_white: Optional[Dict[str, Any]] = None\\n        self.history: List[Dict[str, Any]] = []\\n\\n    def to_dict(self) -> Dict[str, Any]:\\n        return {\\n            \\"session_id\\": self.session_id,\\n            \\"persona\\": self.persona,\\n            \\"difficulty\\": self.difficulty,\\n            \\"task\\": self.task,\\n            \\"turn\\": self.turn,\\n            \\"last_white\\": self.last_white,\\n            \\"history\\": self.history,\\n        }\\n\\nSESSIONS: Dict[str, SessionState] = {}\\n\\napp = FastAPI(title=\\"CRM Arena Pro â€” Green A2A Server\\", version=\\"0.1\\")\\nfrom fastapi.middleware.cors import CORSMiddleware\\n\\napp.add_middleware(\\n    CORSMiddleware,\\n    allow_origins=[\\"http://localhost:9200\\", \\"http://127.0.0.1:9200\\"],\\n    allow_credentials=True,\\n    allow_methods=[\\"*\\"],\\n    allow_headers=[\\"*\\"],\\n)\\n\\n@app.get(\\"/a2a/card\\")\\nasync def card():\\n    return {\\"protocol\\": A2A_VERSION, \\"capabilities\\": [\\"observation\\", \\"feedback\\"], \\"tasks\\": [t[\\"task_id\\"] for t in TASKS]}\\n\\n@app.get(\\"/sessions/{session_id}\\")\\nasync def get_session(session_id: str):\\n    state = SESSIONS.get(session_id)\\n    if not state:\\n        raise HTTPException(status_code=404, detail=\\"session not found\\")\\n    return state.to_dict()\\n\\nasync def _post_to_white(history_payload: Dict[str, Any]) -> Dict[str, Any]:\\n    async with httpx.AsyncClient(timeout=60) as client:\\n        resp = await client.post(WHITE_URL, json=history_payload)\\n        resp.raise_for_status()\\n        return resp.json()\\n\\ndef _policy() -> ProposalPolicy:\\n    return ProposalPolicy(allowed_domains=ALLOWED_DOMAINS)\\n\\n@app.post(\\"/a2a/start\\")\\nasync def start_a2a(\\n    persona: str = Query(\\"ServiceAgent\\", description=\\"ServiceAgent | Analyst | Manager\\"),\\n    difficulty: str = Query(\\"easy\\", description=\\"easy | medium | hard\\"),\\n):\\n    try:\\n        task = pick_task(persona, difficulty)\\n    except KeyError as e:\\n        raise HTTPException(400, str(e))\\n\\n    session_id = str(uuid.uuid4())\\n    state = SessionState(session_id, persona, difficulty, task)\\n    SESSIONS[session_id] = state\\n\\n    obs = make_observation(\\n        session_id=session_id,\\n        turn=state.turn,\\n        context=\\"CRM Arena Pro evaluation session\\",\\n        case_id=task[\\"task_id\\"],\\n        instruction=task[\\"instruction\\"],\\n        constraints={\\"max_round\\": MAX_ROUNDS, \\"metric\\": task[\\"success_criteria\\"]},\\n        schema={\\"note\\": \\"In A2A mode, white executes its own tools and echoes request+result.\\"}\\n    )\\n    state.history.append(obs.dict())\\n\\n    history_payload = _build_full_history_envelope(state)\\n\\n    try:\\n        white_msg = await _post_to_white(history_payload)\\n    except Exception as e:\\n        raise HTTPException(502, f\\"white agent error: {e}\\")\\n\\n    state.last_white = white_msg\\n    state.turn += 1\\n    state.history.append(white_msg)\\n\\n    if white_msg.get(\\"type\\") == \\"action_proposal\\":\\n        try:\\n            proposal = ActionProposal(**white_msg)\\n        except Exception as e:\\n            fb = make_feedback_error(session_id, state.turn, f\\"Malformed proposal: {e}\\")\\n            state.history.append(fb.dict())\\n            return JSONResponse(content={\\"session_id\\": session_id, \\"feedback\\": fb.dict()})\\n        v = validate_action_proposal(proposal, _policy())\\n        fb = make_feedback_ok(session_id, state.turn, v.notes or \\"ok\\", observation_echo=proposal.content.dict())\\n        state.history.append(fb.dict())\\n        return JSONResponse(content={\\"session_id\\": session_id, \\"feedback\\": fb.dict(), \\"done\\": False})\\n\\n    if white_msg.get(\\"type\\") == \\"decision\\":\\n        try:\\n            decision = Decision(**white_msg)\\n        except Exception as e:\\n            raise HTTPException(400, f\\"Malformed decision: {e}\\")\\n  '... 7639 more characters
myapp-backend  |     },
myapp-backend  |     request: <ref *1> ClientRequest {
myapp-backend  |       _events: [Object: null prototype],
myapp-backend  |       _eventsCount: 7,
myapp-backend  |       _maxListeners: undefined,
myapp-backend  |       outputData: [],
myapp-backend  |       outputSize: 0,
myapp-backend  |       writable: true,
myapp-backend  |       destroyed: false,
myapp-backend  |       _last: true,
myapp-backend  |       chunkedEncoding: false,
myapp-backend  |       shouldKeepAlive: false,
myapp-backend  |       maxRequestsOnConnectionReached: false,
myapp-backend  |       _defaultKeepAlive: true,
myapp-backend  |       useChunkedEncodingByDefault: true,
myapp-backend  |       sendDate: false,
myapp-backend  |       _removedConnection: false,
myapp-backend  |       _removedContLen: false,
myapp-backend  |       _removedTE: false,
myapp-backend  |       strictContentLength: false,
myapp-backend  |       _contentLength: '17641',
myapp-backend  |       _hasBody: true,
myapp-backend  |       _trailer: '',
myapp-backend  |       finished: true,
myapp-backend  |       _headerSent: true,
myapp-backend  |       _closed: false,
myapp-backend  |       socket: [TLSSocket],
myapp-backend  |       _header: 'POST /v1/chat/completions HTTP/1.1\r\n' +
myapp-backend  |         'Accept: application/json, text/plain, */*\r\n' +
myapp-backend  |         'Content-Type: application/json\r\n' +
myapp-backend  |         'Authorization: Bearer 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\r\n' +
myapp-backend  |         'User-Agent: axios/1.7.7\r\n' +
myapp-backend  |         'Content-Length: 17641\r\n' +
myapp-backend  |         'Accept-Encoding: gzip, compress, deflate, br\r\n' +
myapp-backend  |         'Host: api.openai.com\r\n' +
myapp-backend  |         'Connection: close\r\n' +
myapp-backend  |         '\r\n',
myapp-backend  |       _keepAliveTimeout: 0,
myapp-backend  |       _onPendingData: [Function: nop],
myapp-backend  |       agent: [Agent],
myapp-backend  |       socketPath: undefined,
myapp-backend  |       method: 'POST',
myapp-backend  |       maxHeaderSize: undefined,
myapp-backend  |       insecureHTTPParser: undefined,
myapp-backend  |       joinDuplicateHeaders: undefined,
myapp-backend  |       path: '/v1/chat/completions',
myapp-backend  |       _ended: true,
myapp-backend  |       res: [IncomingMessage],
myapp-backend  |       aborted: false,
myapp-backend  |       timeoutCb: null,
myapp-backend  |       upgradeOrConnect: false,
myapp-backend  |       parser: null,
myapp-backend  |       maxHeadersCount: null,
myapp-backend  |       reusedSocket: false,
myapp-backend  |       host: 'api.openai.com',
myapp-backend  |       protocol: 'https:',
myapp-backend  |       _redirectable: [Writable],
myapp-backend  |       [Symbol(kCapture)]: false,
myapp-backend  |       [Symbol(kBytesWritten)]: 0,
myapp-backend  |       [Symbol(kNeedDrain)]: false,
myapp-backend  |       [Symbol(corked)]: 0,
myapp-backend  |       [Symbol(kOutHeaders)]: [Object: null prototype],
myapp-backend  |       [Symbol(errored)]: null,
myapp-backend  |       [Symbol(kHighWaterMark)]: 16384,
myapp-backend  |       [Symbol(kRejectNonStandardBodyWrites)]: false,
myapp-backend  |       [Symbol(kUniqueHeaders)]: null
myapp-backend  |     },
myapp-backend  |     data: { error: [Object] }
myapp-backend  |   },
myapp-backend  |   status: 400
myapp-backend  | }
